{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-lab1-tokenize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPLXM65WSJ0U1ZkZwhTejdu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/turuuschs/Sict-NLP/blob/master/lab1_tokenize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XRBpmTVvKGt",
        "colab_type": "text"
      },
      "source": [
        "## Stanford-ийн эх хэлний сан"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dteFo4q4s0Px",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "033a8ff4-c42b-4569-ba5c-3edd13864545"
      },
      "source": [
        "!pip install stanfordnlp\n",
        "import stanfordnlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stanfordnlp in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (2.21.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (1.18.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (2019.11.28)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp) (46.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSxST0e5vUFu",
        "colab_type": "text"
      },
      "source": [
        "## Үгээр токенчлол"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTD738SOrhVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "f6ca2a8e-e311-4d20-9a6d-cdcff1fd2a07"
      },
      "source": [
        "# Уншсан болон дагаж хийсэн эх сурвалж:\n",
        "# https://stanfordnlp.github.io/stanfordnlp/tokenize.html\n",
        "\n",
        "nlp = stanfordnlp.Pipeline(processors='tokenize', lang='en', tokenize_pretokenized=True)\n",
        "doc = nlp(\"Эхний лаб бөгөөд энэ өгүүлбэр эхний өгүүлбэр болно \\nМөн хоёр дахь өгүүлбэр!\")\n",
        "for i, sentence in enumerate(doc.sentences):\n",
        "    print(f\"====== {i+1}-р өгүүлбэрийн токенчлол  =======\")\n",
        "    print(*[f\"index: {token.index.rjust(3)}\\ttoken: {token.text}\" for token in sentence.tokens], sep='\\n')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: cpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'pretokenized': True, 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n",
            "====== 1-р өгүүлбэрийн токенчлол  =======\n",
            "index:   1\ttoken: Эхний\n",
            "index:   2\ttoken: лаб\n",
            "index:   3\ttoken: бөгөөд\n",
            "index:   4\ttoken: энэ\n",
            "index:   5\ttoken: өгүүлбэр\n",
            "index:   6\ttoken: эхний\n",
            "index:   7\ttoken: өгүүлбэр\n",
            "index:   8\ttoken: болно\n",
            "====== 2-р өгүүлбэрийн токенчлол  =======\n",
            "index:   1\ttoken: Мөн\n",
            "index:   2\ttoken: хоёр\n",
            "index:   3\ttoken: дахь\n",
            "index:   4\ttoken: өгүүлбэр!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}